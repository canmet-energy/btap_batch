# Parametric Analysis Local Machine

A parametric, or full-factorial analysis is simply going through all options in a giving input file. 





1. To run a parametric analysis, go to the example.yml analysis file in the 'examples/parametric' folder. Each 
parameter is explained in that file. Ensure that parametric analysis is a reasonable size for your system (i.e. Do not 
run millions of simulations on your 2 core laptop). Ensure that the ':compute_environment' variable is set to local.  
2. Please ensure that the btap_batch python venv environment is active. If it is not, run the following from the project folder. 
```
venv\Scripts\activate.bat
```

You can run the analysis using the run-analysis-project. You can inspect the switches available for this comm
```
python ./bin/btap_batch.py run-analysis-project --compute_environment local --project_folder C:\Users\plopez\btap_batch\examples\parametric --reference_run
```
3. Simulation should start to run. A folder will be created in output folder with the variable name you set 
':analysis_name' in the yml file. In that folder you will see two folders, 'parametric' and 'reference'. 'reference' 
contains the reference run analysis. This is the information use to compare the 'parametric' runs against. both of these folders
contain a 'runs' folder and 'results' folder.  


### Output
* The runs folder contains folders with uuids for all the simulations that you are running. It contains the 
run_options.yml file. This contains the selections created for that particular run. This contains all the input and 
output files from OS/Energyplus.

* The results folder contains the summary results of all the simulations. 
    * The database folder contains all the csv outputs from each run.
    * The eplustbl.htm folder contains the energyplus html output for each run. 
    * The failures folder contain the input files that did not simulation correctly. 
    * The hourly.csv folder contains the hourly data requested for each simulation. 
    * The in.osm contains the OpenStudio osm file used for each simulation. 
    * The output.xlsx is an excel file that contains the results from all the simulations.  

## Using Amazon AWS for analysis
1. Ensure you are not connected to a VPN and do not connect while running simulations.
2. Change '-compute_environment' to local_managed_aws_workers (note that ':compute_environment' is in example.yml analysis file in the 'example' folder).
3. Update your AWS credentials to ensure it is up to date through your AWS Account -> btap-dev -> Command line and programmatic Access. Copy the Text in 'Option 2'.
4. Use your updated AWS credentials in '.aws/credentials' file in your user folder.
*Note*:  Navigate to '.aws' folder in your user folder using windows powershell. Run the command: ```$ aws configure```. Set the default region name to ca-central-1, and output format to json. Then, open the generated credentials file in '.aws' folder in your user folder. Use your updated AWS credentials in the credentials file. Replace the first line that looks something like this [834599497928_PowerUser] to [default] and save the file.

```
python ./bin/btap_batch.py run-analysis-project --compute_environment local_managed_aws_workers --project_folder C:\Users\plopez\btap_batch\examples\parametric --run_reference
```

The output of the runs is not stored all locally, but on the S3 Bucket,  the ':analysis_name' you chose and the analysis_id 
generated by the script. For example, if you ran the analysis with the analysis_name: set to 'example_analysis', the default 
:s3_bucket is '834599497928' for the nrcan account, and your aws username is 'phylroy.lopez'. The runs would be kept on S3 in a path like
```
s3://<:s3_bucket_name>/<your_user_name>/<:analysis_name>/
```
*Note*: This script will not delete anything from S3. So you must delete your S3 folders yourself.

